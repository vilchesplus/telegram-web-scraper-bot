#+title: Anotaciones
#+options: toc:nil

[[https://github.com/vilchesplus/telegram-web-scraper-bot]]


[[https://hub.docker.com/u/vilchesplus]]


Tenemos 2 *scripts* que nos facilitan el web-scraping y monitorización de:
- Estado de una web.
- Última versión de un software concreto.

Está escrito en Python, y se proporciona un *token* que corresponde con un bot de Telegram para que nos envíe la información de manera temporal.

Basta con ejecutar cualquiera de los scripts y ya estaría funcionando.

** DONE Añadir Fecha y hora del último dato cargado en la página web.

Se ha añadido el script de Python scrapeo utilizando Selenium y un driver de Chrome para obtener el dato que comentamos, ya que realizando un scrapeo normal no es posible debido a que y cito textualmente "La fuente es sólo el HTML base que se sirve. Cuando inspeccionas la página en Chrome, estás viendo el DOM renderizado después de que cualquier javascript en la página haya terminado de hacer su trabajo. En otras palabras, los elementos que buscas pueden ser creados dinámicamente".

[[./images/features.PNG]]

[[./mensajes-recibido.jpeg]]



Otra manera de acuerdo con la manera de trabajar que se está instaurando es la siguiente:

** DONE Objetivo: CI/CD
 La combinación de la integración continua y el despliegue se denomina a menudo CI/CD.
Un pipeline típico para aplicaciones en contenedor podría ser como el siguiente:
1. Un desarrollador empuja sus cambios de código al repositorio.
   
2. El sistema de construcción construye automáticamente la versión actual del código y ejecuta pruebas.

3. Si todas las pruebas pasan, la imagen del contenedor se publicará en el registro central de contenedores.

4. El contenedor recién construido se despliega automáticamente en un entorno de preparación.
   
5. El entorno de ensayo se somete a algunas pruebas de aceptación automatizadas y/o manuales.
 
6. La imagen del contenedor verificada se despliega en producción.

*** Instalación de Jenkins como herramienta CI/CD   
Creamos el archivo .yaml con el que levantaremos *Jenkins* y *Sonarqube*

#+begin_src shell
version: '2'
services:
  jenkins:
   image: vilchesplus/jenkins-blueocean-ci
   container_name: jenkins
   ports:
    - "8080:8080"
    - "50000:50000"
  sonarqube:
   image: sonarqube
   container_name: sonarqube
   ports:
    - "9000:9000"
    - "9092:9092"
#+end_src

Accedemos vía *localhost:8080* al servicio de Jenkins. E instalamos el plugin de *SonarQube Scanner* y *CloudBees Docker Build and Publish plugin*


El /pipeline/ creado sería el siguiente:
[[./images/pipeline.drawio.png]]

Necesitaremos también abrir una conexión tunel entre github y Jenkins, mediante *ngrok*. ngrok nos permite exponer a internet una URL generada dinámicamente, la cual apunta a un servicio web que se está ejecutando en nuestra máquina local.
#+begin_src shell
ngrok http 8080
#+end_src

** DONE Ejecutar desde la nube los contenedores.
[[./images/instancias.PNG]]


** TODO Añadir SSH Plugin sobre Jenkins.
La idea es conseguir conexión vía ssh desde el contenedor hacia la instancia de ec2.
[[https://faun.pub/use-jenkins-to-run-scripts-in-aws-ec2-1f3d1307263a]]

** DONE Pasar de Docker a Kubernetes (facilidad para levantar los contenedores de manera automática ante errores ocasionados, o tener replicas desplegadas)   

[[./Aplicaciones.PNG]]

[[./despliegue-en-local.PNG]]




